{"cells":[{"cell_type":"markdown","metadata":{},"source":["## Preface\n\n"]},{"cell_type":"markdown","metadata":{},"source":["If need be&#x2026;\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["!pip install CFEDemands\n!pip install oauth2client\n!pip install dvc"]},{"cell_type":"markdown","metadata":{},"source":["## Introduction\n\n"]},{"cell_type":"markdown","metadata":{},"source":["Here we give a set of generic instructions for analyzing demand for\nfood and nutrition.  Inputs include a datasets of consumption\nquantities, consumption expenditures, household characteristics, and a\nfood conversion table.\n\nThe different datasets should be indexed as follows:\n\n| Dataset|Indexed by|Columns|\n|---|---|---|\n| Expenditures|j,t,m|i|\n| Consumption|j,t,m,u|i|\n| HH Characteristics|j,t,m|k|\n| FCT|i,u|n|\n| RDI|n|k|\n\nwhere `j` indexes households, `t` indexes periods, `m` indexes\nmarkets, `i` indexes goods, `k` indexes different kinds of household\ncharacteristics, `u` indexes different unit names, and `n` indexes\ndifferent nutrients.  Finally, any RDI (&ldquo;recommended daily intake&rdquo;)\ntables should be indexed by nutrients, with columns corresponding to\ncharacteristics of persons within the household (e.g., age & sex\ncategories).\n\nNote that some countries have more than one dataframe of consumption,\ndistinguished by source; for example Malawi has consumption items\npurchased as well as consumption items produced.  Here we focus on\nconsumption purchases, since one of our immediate aims is to infer\nprices paid.\n\n"]},{"cell_type":"markdown","metadata":{},"source":["### Step 1: Acquire DataFrames\n\n"]},{"cell_type":"markdown","metadata":{},"source":["Here are addresses of google sheets for different dataframes for the\ncase of Niger:\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["InputFiles = {'Expenditures':('1ySP8lrXlQ2ChaMdz0HQY85Md65cRRKOZgz-T0zBN2K0','Expenditures'),\n              'Consumption':('1kr2NI57xiTQm20A_68NEcLKihVTJw2ZgWCwV98ZD4JE','Consumption'),\n              'HH Characteristics':('1ySP8lrXlQ2ChaMdz0HQY85Md65cRRKOZgz-T0zBN2K0','HH Characteristics'),\n              'FCT':('1TM7FpKURXFAuXW4dLpGt98QA2CH4WTDty-4nPOUv1Mg','05 NV_sum_57 (per 100g EP)')}"]},{"cell_type":"markdown","metadata":{},"source":["Note that the food items for the FCT for Niger are **not** yet matched\nup with food labels indexed by `i` in the expenditure and consumption datasets.\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["from eep153_tools import read_sheets\nimport numpy as np\nimport pandas as pd\n\ndef get_clean_sheet(key,json_creds,sheet=None):\n\n    df = read_sheets(key,json_creds,sheet)\n    df.columns = [c.strip() for c in df.columns.tolist()]\n\n    df = df.loc[:,~df.columns.duplicated(keep='first')]   \n\n    df = df.drop([col for col in df.columns if col.startswith('Unnamed')], axis=1)\n\n    df = df.loc[~df.index.duplicated(), :]\n\n    return df\n\n# Get expenditures...\nx = get_clean_sheet(InputFiles['Expenditures'][0],\n                    json_creds='../students-9093fa174318.json',\n                    sheet=InputFiles['Expenditures'][1])\n\nif 'm' not in x.columns:\n    x['m'] = 1\n\nx = x.set_index(['j','t','m'])\nx.columns.name = 'i'\n\nx = x.apply(lambda x: pd.to_numeric(x,errors='coerce'))\nx = x.replace(0,np.nan)\n\n# Get HH characteristics...\nz = get_clean_sheet(InputFiles['HH Characteristics'][0],\n                    json_creds='../students-9093fa174318.json',\n                    sheet=InputFiles['HH Characteristics'][1])\n\nif 'm' not in z.columns:\n    z['m'] = 1\n\nz = z.set_index(['j','t','m'])\nz.columns.name = 'k'\n\nz = z.apply(lambda x: pd.to_numeric(x,errors='coerce'))\n\n# Get purchased consumption quantities\nq = get_clean_sheet(InputFiles['Consumption'][0],\n                    json_creds='../students-9093fa174318.json',\n                    sheet=InputFiles['Consumption'][1])\n\nif 'm' not in q.columns:\n    q['m'] = 1\n\nq = q.set_index(['j','t','m','u'])\nq.columns.name = 'i'\n\nq = q.apply(lambda x: pd.to_numeric(x,errors='coerce'))\nq = q.replace(0,np.nan)\n\nfct = get_clean_sheet(InputFiles['FCT'][0],\n                    json_creds='../students-9093fa174318.json',\n                    sheet=InputFiles['FCT'][1])\n\n#### This bit peculiar to Niger FCT #####\nfct = fct.loc[fct.Code.str.len()==6]\nfct = fct.set_index('Code')\nfct.columns = [v.replace('\\n',' ') for v in fct.columns]\n########################################\n\nfct.index.name = 'i'\n\nfct = fct.apply(lambda x: pd.to_numeric(x,errors='coerce'))"]},{"cell_type":"markdown","metadata":{},"source":["### Step 2: Estimate Demand System\n\n"]},{"cell_type":"markdown","metadata":{},"source":["Here, use data on log *expenditures* and household characteristics to\ncreate a CFEDemand `result`.\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import cfe\n\nresult = cfe.Result(y=np.log(x),z=z)\n\n# Estimates most things (not counting std errors for betas).\nxhat = result.get_predicted_expenditures() \n\nresult.get_beta(as_df=True).sort_values(ascending=False) # Check sanity..."]},{"cell_type":"markdown","metadata":{},"source":["### Step 3: Infer prices\n\n"]},{"cell_type":"markdown","metadata":{},"source":["Next, we divide predicted expenditures by actual quantities to get\nprices, then choose prices corresponding to some units (e.g.,\nkilograms) we can map into the  FCT.\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["# xhat is an xarray; change q\nq = q.to_xarray().to_array('i')\nphat = (xhat/q).to_dataframe('p').squeeze().unstack('i')\n\n# Keep kgs; g\nphat = phat.xs('kg',level='u').groupby(['t','m']).median().dropna(how='all')"]},{"cell_type":"markdown","metadata":{},"source":["### Step 4: Predicting Positive Consumption\n\n"]},{"cell_type":"markdown","metadata":{},"source":["An issue with our assessment of fit is that we *predicted* that every\nhousehold would consume positive quantitites of every good, and in\nmaking our assessment we ignored the (many) cases in which in fact the\nhousehold had zero expenditures on that good.  \n\nHere we&rsquo;re going to go back and use similar framework to try and\nestimate the probability with which we&rsquo;ll observe zero expenditures\nas a function of &lambda;, prices, and household characteristics.\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import matplotlib.pyplot as plt\n%matplotlib inline\nimport matplotlib.cm as cm\n\nzeros_r = cfe.Result(y=(0.+(result.y>0)),z=result.z)\nweights = zeros_r.get_predicted_log_expenditures()\n\n# Truncate to make weights live in [0,1]\nweights = weights.where((weights<1) + np.isnan(weights),1).where((weights>0) + np.isnan(weights),0)\n\nxbar = np.exp(result.y).sum(['m','i']).to_dataframe('xbar').replace(0,np.nan).squeeze()\n\n# Calculate *expected* predicted expenditures, to make unconditional on being positive\nxhat = (weights*result.get_predicted_expenditures())\nxsum = xhat.sum(['m','i']).to_dataframe('xhat').replace(0,np.nan).squeeze()\n\n# Make dataframe of actual & predicted\ndf = pd.DataFrame({'Actual':np.log(xbar),'Predicted':np.log(xsum)})\n\ndf.plot.scatter(x='Predicted',y='Actual')\n\n# Add 45 degree line\nv = plt.axis()\nvmin = np.max([v[0],v[2]])\nvmax = np.max([v[1],v[3]])\nplt.plot([vmin,vmax],[vmin,vmax])"]},{"cell_type":"markdown","metadata":{},"source":["### Step 5: Get predicted quantities\n\n"]},{"cell_type":"markdown","metadata":{},"source":["Now divide predicted expenditures by predicted prices to get predicted\nquantities, and put back into a dataframe.\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["qhat = xhat/phat.to_xarray().to_array('i')\n\nqhat = qhat.to_dataframe('q').unstack('i')\n\nqhat.columns = qhat.columns.droplevel(0)"]},{"cell_type":"markdown","metadata":{},"source":["### Step 6: Map predicted quantities into nutrients\n\n"]},{"cell_type":"markdown","metadata":{},"source":["May need some work to clean up the FCT, and create food names/indices\ncorresponding to the `i` index in `qhat`.\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["print(pd.Series(xhat.coords['i']).to_markdown())"]},{"cell_type":"markdown","metadata":{},"source":["| Niger Labels|WAFCT Codes|\n|---|---|\n| Baobab leaves|04<sub>001</sub>|\n| Bean fritters|03<sub>054</sub>|\n| Beans|03<sub>022</sub>|\n| Beef|07<sub>014</sub>|\n| Biscuit|01<sub>188</sub>|\n| Bowl of millet with milk|01<sub>174</sub>|\n| Bowl of millet without milk|01<sub>167</sub>|\n| Bread|01<sub>047</sub>|\n| Cakes|01<sub>187</sub>|\n| Cassava tuber|02<sub>021</sub>|\n| Cigarette||\n| Coffee in cans|12<sub>009</sub>|\n| Cola nut|06<sub>018</sub>|\n| Corn|04<sub>109</sub>|\n| Corn fritters|01<sub>123</sub>|\n| Cornstarch||\n| Curd|10<sub>028</sub>|\n| Dates|05<sub>031</sub>|\n| Dry okra|04<sub>077</sub>|\n| Eggs|08<sub>001</sub>|\n| Fresh Okra|04<sub>017</sub>|\n| Fresh Onion|04<sub>018</sub>|\n| Fresh fish|09<sub>060</sub>|\n| Fresh pepper|04<sub>049</sub>|\n| Fresh tomato|04<sub>021</sub>|\n| Fruit juice|12<sub>013</sub>|\n| Goat meat|07<sub>069</sub>|\n| Groundnut cake|03<sub>012</sub>|\n| Juice powder||\n| Maggi cube||\n| Malahya||\n| Millet|01<sub>095</sub>|\n| Mutton|07<sub>004</sub>|\n| Orange|05<sub>016</sub>|\n| Other citrus||\n| Other spices||\n| Palm oil|11<sub>007</sub>|\n| Pasta|01<sub>077</sub>|\n| Peanut butter|06<sub>023</sub>|\n| Peanut oil|11<sub>003</sub>|\n| Pimento||\n| Potato|02<sub>009</sub>|\n| Poultry|08<sub>010</sub>|\n| Powdered milk|10<sub>002</sub>|\n| Rice|01<sub>065</sub>|\n| Rice &tomato sauce||\n| Rice cowpea|03<sub>143</sub>|\n| Salad||\n| Salt|13<sub>015</sub>|\n| Soft Drinks|12<sub>024</sub>|\n| Soumbala|03<sub>042</sub>|\n| Squash|04<sub>051</sub>|\n| Sugar|13<sub>002</sub>|\n| Sugar cane||\n| Sweet banana|05<sub>048</sub>|\n| Sweet potato|02<sub>049</sub>|\n| Tea bag|12<sub>008</sub>|\n| Tomato paste|04<sub>066</sub>|\n| Yam tuber|02<sub>019</sub>|\n| Yodo||\n| Yogurt|10<sub>005</sub>|\n\nThese particular clean-ups are peculiar to the West African FCT.\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["# Dictionary mapping index i to fct codes\ni_to_fct = pd.read_csv('niger_fct_codes.csv').dropna().set_index('Niger Labels').squeeze().to_dict()\n\n# Create version of qhat with fct ids for labels\nmyq = qhat.rename(columns=i_to_fct)[list(i_to_fct.values())]\n\n# Drop goods with no obs, households with no goods\nmyq = myq.dropna(how='all',axis=1).dropna(how='all')\n\n# Create version of fct with just foods in myq\nmyfct=fct.loc[myq.columns].iloc[:,8:] # Drop columns which aren't nutrients"]},{"cell_type":"markdown","metadata":{},"source":["Before this will work, need columns of qhat to match columns of fct.\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["nutrients = myq@myfct\nnutrients.mean()    # NB: Nutrients are for past /week/ for entire household."]}],"metadata":{"org":null,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"}},"nbformat":4,"nbformat_minor":0}